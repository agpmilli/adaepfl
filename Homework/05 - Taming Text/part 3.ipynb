{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import\n",
    "Add \"from gensim import models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alain\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:840: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\Alain\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n",
      "C:\\Users\\Alain\\Anaconda3\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "#required imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import string\n",
    "import collections\n",
    "import re\n",
    "import pycountry\n",
    "from gensim import models, corpora\n",
    "from os import path\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import bigrams\n",
    "from nltk import ngrams\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.tokenize import treebank\n",
    "import sentiment as senth\n",
    "\n",
    "\n",
    "#local helper file import\n",
    "import nlp_helper as nlph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExtractedSubject</th>\n",
       "      <th>ExtractedBodyText</th>\n",
       "      <th>RawText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FW: Wow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNCLASSIFIED\\r\\nU.S. Department of State\\r\\nCa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>B6\\r\\nThursday, March 3, 2011 9:45 PM\\r\\nH: La...</td>\n",
       "      <td>UNCLASSIFIED\\r\\nU.S. Department of State\\r\\nCa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Re: Chris Stevens</td>\n",
       "      <td>Thx</td>\n",
       "      <td>UNCLASSIFIED\\r\\nU.S. Department of State\\r\\nCa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FVV: Cairo Condemnation - Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNCLASSIFIED\\r\\nU.S. Department of State\\r\\nCa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>H &lt;hrod17@clintonemail.com&gt;\\r\\nFriday, March 1...</td>\n",
       "      <td>B6\\r\\nUNCLASSIFIED\\r\\nU.S. Department of State...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ExtractedSubject  \\\n",
       "0                          FW: Wow   \n",
       "1                              NaN   \n",
       "2                Re: Chris Stevens   \n",
       "3  FVV: Cairo Condemnation - Final   \n",
       "4                              NaN   \n",
       "\n",
       "                                   ExtractedBodyText  \\\n",
       "0                                                NaN   \n",
       "1  B6\\r\\nThursday, March 3, 2011 9:45 PM\\r\\nH: La...   \n",
       "2                                                Thx   \n",
       "3                                                NaN   \n",
       "4  H <hrod17@clintonemail.com>\\r\\nFriday, March 1...   \n",
       "\n",
       "                                             RawText  \n",
       "0  UNCLASSIFIED\\r\\nU.S. Department of State\\r\\nCa...  \n",
       "1  UNCLASSIFIED\\r\\nU.S. Department of State\\r\\nCa...  \n",
       "2  UNCLASSIFIED\\r\\nU.S. Department of State\\r\\nCa...  \n",
       "3  UNCLASSIFIED\\r\\nU.S. Department of State\\r\\nCa...  \n",
       "4  B6\\r\\nUNCLASSIFIED\\r\\nU.S. Department of State...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raws = pd.read_csv('hillary-clinton-emails/Emails.csv',usecols=['ExtractedSubject','ExtractedBodyText','RawText'])\n",
    "raws.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raws.drop(['RawText'], axis= 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExtractedSubject</th>\n",
       "      <th>ExtractedBodyText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FW: Wow</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>B6\\r\\nThursday, March 3, 2011 9:45 PM\\r\\nH: La...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Re: Chris Stevens</td>\n",
       "      <td>Thx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FVV: Cairo Condemnation - Final</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>H &lt;hrod17@clintonemail.com&gt;\\r\\nFriday, March 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ExtractedSubject  \\\n",
       "0                          FW: Wow   \n",
       "1                              NaN   \n",
       "2                Re: Chris Stevens   \n",
       "3  FVV: Cairo Condemnation - Final   \n",
       "4                              NaN   \n",
       "\n",
       "                                   ExtractedBodyText  \n",
       "0                                                NaN  \n",
       "1  B6\\r\\nThursday, March 3, 2011 9:45 PM\\r\\nH: La...  \n",
       "2                                                Thx  \n",
       "3                                                NaN  \n",
       "4  H <hrod17@clintonemail.com>\\r\\nFriday, March 1...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raws.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "body = pd.DataFrame()\n",
    "body['text'] = raws.apply(nlph.concat_subj_txt, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "stop.update(string.punctuation) #Remove ponctuation\n",
    "stop.update(['nan', '\\'s', '--', '``', 'w', 'fw', 'n\\'t', '\\'m', 'also', 'thx', 'fyi', 'pls', '\\'\\'', '-', '—', 'pm', '•'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "body_tokenized = [[i for i in word_tokenize(text.lower())if i not in stop] for text in body['text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 Topic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dictionary and the corpus using the tokenized body of the emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(body_tokenized)\n",
    "corpus = [dictionary.doc2bow(text) for text in body_tokenized]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then build the LDA Model with number of topics between 5 to 50 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(5,50,5):\n",
    "    lda = models.LdaModel(corpus, id2word=dictionary, num_topics=i)\n",
    "    print(\"This model contains \", i , \" topics and we define each topic by 5 words :\")\n",
    "    print(lda.print_topics(num_topics=lda.num_topics, num_words=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
