{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Applied ML\n",
    "\n",
    "## Deadline\n",
    "Monday November 21, 2016 at 11:59PM\n",
    "\n",
    "## Important Notes\n",
    "* Make sure you push on GitHub your Notebook with all the cells already evaluated\n",
    "* Don't forget to add a textual description of your thought process, the assumptions you made, and the solution\n",
    "you plan to implement!\n",
    "* Please write all your comments in English, and use meaningful variable names in your code\n",
    "\n",
    "## Background\n",
    "In this homework we will gain experience on Applied Machine Learning, exploring an interesting dataset about soccer players and referees.\n",
    "You can find all the data in the `CrowdstormingDataJuly1st.csv` file, while you can read a thorough [dataset description here](DATA.md).\n",
    "Given that the focus of this homework is Machine Learning, I recommend you to first take a look at [this notebook](http://nbviewer.jupyter.org/github/mathewzilla/redcard/blob/master/Crowdstorming_visualisation.ipynb)\n",
    "containing a solid work in pre-processing + visualization of the given dataset. You are *not* allowed to just copy/paste the pre-processing steps\n",
    "performed by the notebook authors -- you are still supposed to perform your own data analysis for the homework. Still, I'm confident that consulting first\n",
    "the work done by expert data analysts will speed up tangibly your effort (i.e., they have already found for you many glitches in the data :)\n",
    "\n",
    "\n",
    "## Assignment\n",
    "1. Train a `sklearn.ensemble.RandomForestClassifier` that given a soccer player description outputs his skin color. Show how different parameters \n",
    "passed to the Classifier affect the overfitting issue. Perform cross-validation to mitigate the overfitting of your model. Once you assessed your model,\n",
    "inspect the `feature_importances_` attribute and discuss the obtained results. With different assumptions on the data (e.g., dropping certain features even\n",
    "before feeding them to the classifier), can you obtain a substantially different `feature_importances_` attribute?\n",
    "*BONUS*: plot the learning curves against at least 2 different sets of parameters passed to your Random Forest. To obtain smooth curves, partition\n",
    "your data in at least 20 folds. Can you find a set of parameters that leads to high bias, and one which does not?\n",
    "\n",
    "2. Aggregate the referee information grouping by soccer player, and use an unsupervised learning technique to cluster the soccer players in 2 disjoint\n",
    "clusters. Remove features iteratively, and at each step perform again the clustering and compute the silhouette score -- can you find a configuration of features with high silhouette\n",
    "score where players with dark and light skin colors belong to different clusters? Discuss the obtained results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------\n",
    "# Data Description\n",
    "\n",
    "From a company for sports statistics, we obtained data and profile photos from all soccer players (N = 2053) playing in the first male divisions of England, Germany, France and Spain in the 2012-2013 season and all referees (N = 3147) that these players played under in their professional career. We created a dataset of player–referee dyads including the number of matches players and referees encountered each other and our dependent variable, the number of red cards given to a player by a particular referee throughout all matches the two encountered each other.\n",
    " \n",
    "Player photos were available from the source for 1586 out of 2053 players. Players’ skin tone was coded by two independent raters blind to the research question who, based on their profile photo, categorized players on a 5-point scale ranging from “very light skin” to “very dark skin” with “neither dark nor light skin” as the center value. \n",
    "\n",
    "Additionally, implicit bias scores for each referee country were calculated using a race implicit association test (IAT), with higher values corresponding to faster white | good, black | bad associations. Explicit bias scores for each referee country were calculated using a racial thermometer task, with higher values corresponding to greater feelings of warmth toward whites versus blacks. Both these measures were created by aggregating data from many online users in referee countries taking these tests on [Project Implicit](http://projectimplicit.net).\n",
    "\n",
    "In all, the dataset has a total of 146028 dyads of players and referees. A detailed description of all variables in the dataset can be seen in the list below.\n",
    "\n",
    "## Variables:\n",
    "\n",
    "*playerShort* - short player ID\n",
    "\n",
    "*player* - player name\n",
    "\n",
    "*club* - player club\n",
    "\n",
    "*leagueCountry* - country of player club (England, Germany, France, and Spain)\n",
    "\n",
    "*birthday* - player birthday\n",
    "\n",
    "*height* - player height (in cm)\n",
    "\n",
    "*weight* - player weight (in kg)\n",
    "\n",
    "*position* - detailed player position\n",
    "\n",
    "*games* - number of games in the player-referee dyad\n",
    "\n",
    "*victories* - victories in the player-referee dyad\n",
    "\n",
    "*ties* - ties in the player-referee dyad\n",
    "\n",
    "*defeats* - losses in the player-referee dyad\n",
    "\n",
    "*goals* - goals scored by a player in the player-referee dyad\n",
    "\n",
    "*yellowCards* - number of yellow cards player received from referee\n",
    "\n",
    "*yellowReds* - number of yellow-red cards player received from referee\n",
    "\n",
    "*redCards* - number of red cards player received from referee\n",
    "\n",
    "*photoID* - ID of player photo (if available)\n",
    "\n",
    "*rater1* - skin rating of photo by rater 1 (5-point scale ranging from “very light skin” to “very dark skin”)\n",
    "\n",
    "*rater2* - skin rating of photo by rater 2 (5-point scale ranging from “very light skin” to “very dark skin”)\n",
    "\n",
    "*refNum* - unique referee ID number (referee name removed for anonymizing purposes)\n",
    "\n",
    "*refCountry* - unique referee country ID number (country name removed for anonymizing purposes)\n",
    "\n",
    "*meanIAT* - mean implicit bias score (using the race IAT) for referee country, higher values correspond to faster white | good, black | bad associations\n",
    "\n",
    "*nIAT* - sample size for race IAT in that particular country\n",
    "\n",
    "*seIAT* - standard error for mean estimate of race IAT\n",
    "\n",
    "*meanExp* - mean explicit bias score (using a racial thermometer task) for referee country, higher values correspond to greater feelings of warmth toward whites versus blacks\n",
    "\n",
    "*nExp* - sample size for explicit bias in that particular country\n",
    "\n",
    "*seExp* - standard error for mean estimate of explicit bias measure\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# IMPLEMENTATION\n",
    "## Supervised Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import preprocessing_helper as pprh\n",
    "import classifiers_helper as clfh\n",
    "import aggregater as aggr\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "data = 'CrowdstormingDataJuly1st.csv'\n",
    "dyads = pd.read_csv(data)\n",
    "nb_cols = len(dyads.columns)\n",
    "print(nb_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerShort</th>\n",
       "      <th>player</th>\n",
       "      <th>club</th>\n",
       "      <th>leagueCountry</th>\n",
       "      <th>birthday</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>position</th>\n",
       "      <th>games</th>\n",
       "      <th>victories</th>\n",
       "      <th>ties</th>\n",
       "      <th>defeats</th>\n",
       "      <th>goals</th>\n",
       "      <th>yellowCards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lucas-wilchez</td>\n",
       "      <td>Lucas Wilchez</td>\n",
       "      <td>Real Zaragoza</td>\n",
       "      <td>Spain</td>\n",
       "      <td>31.08.1983</td>\n",
       "      <td>177.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>Attacking Midfielder</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>john-utaka</td>\n",
       "      <td>John Utaka</td>\n",
       "      <td>Montpellier HSC</td>\n",
       "      <td>France</td>\n",
       "      <td>08.01.1982</td>\n",
       "      <td>179.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Right Winger</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abdon-prats</td>\n",
       "      <td>Abdón Prats</td>\n",
       "      <td>RCD Mallorca</td>\n",
       "      <td>Spain</td>\n",
       "      <td>17.12.1992</td>\n",
       "      <td>181.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pablo-mari</td>\n",
       "      <td>Pablo Marí</td>\n",
       "      <td>RCD Mallorca</td>\n",
       "      <td>Spain</td>\n",
       "      <td>31.08.1993</td>\n",
       "      <td>191.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>Center Back</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ruben-pena</td>\n",
       "      <td>Rubén Peña</td>\n",
       "      <td>Real Valladolid</td>\n",
       "      <td>Spain</td>\n",
       "      <td>18.07.1991</td>\n",
       "      <td>172.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Right Midfielder</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aaron-hughes</td>\n",
       "      <td>Aaron Hughes</td>\n",
       "      <td>Fulham FC</td>\n",
       "      <td>England</td>\n",
       "      <td>08.11.1979</td>\n",
       "      <td>182.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Center Back</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aleksandar-kolarov</td>\n",
       "      <td>Aleksandar Kolarov</td>\n",
       "      <td>Manchester City</td>\n",
       "      <td>England</td>\n",
       "      <td>10.11.1985</td>\n",
       "      <td>187.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Left Fullback</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>alexander-tettey</td>\n",
       "      <td>Alexander Tettey</td>\n",
       "      <td>Norwich City</td>\n",
       "      <td>England</td>\n",
       "      <td>04.04.1986</td>\n",
       "      <td>180.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Defensive Midfielder</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>anders-lindegaard</td>\n",
       "      <td>Anders Lindegaard</td>\n",
       "      <td>Manchester United</td>\n",
       "      <td>England</td>\n",
       "      <td>13.04.1984</td>\n",
       "      <td>193.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Goalkeeper</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>andreas-beck</td>\n",
       "      <td>Andreas Beck</td>\n",
       "      <td>1899 Hoffenheim</td>\n",
       "      <td>Germany</td>\n",
       "      <td>13.03.1987</td>\n",
       "      <td>180.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Right Fullback</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>antonio-rukavina</td>\n",
       "      <td>Antonio Rukavina</td>\n",
       "      <td>Real Valladolid</td>\n",
       "      <td>Spain</td>\n",
       "      <td>26.01.1984</td>\n",
       "      <td>177.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Right Fullback</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           playerShort              player               club leagueCountry  \\\n",
       "0        lucas-wilchez       Lucas Wilchez      Real Zaragoza         Spain   \n",
       "1           john-utaka          John Utaka    Montpellier HSC        France   \n",
       "2          abdon-prats         Abdón Prats       RCD Mallorca         Spain   \n",
       "3           pablo-mari          Pablo Marí       RCD Mallorca         Spain   \n",
       "4           ruben-pena          Rubén Peña    Real Valladolid         Spain   \n",
       "5         aaron-hughes        Aaron Hughes          Fulham FC       England   \n",
       "6   aleksandar-kolarov  Aleksandar Kolarov    Manchester City       England   \n",
       "7     alexander-tettey    Alexander Tettey       Norwich City       England   \n",
       "8    anders-lindegaard   Anders Lindegaard  Manchester United       England   \n",
       "9         andreas-beck        Andreas Beck    1899 Hoffenheim       Germany   \n",
       "10    antonio-rukavina    Antonio Rukavina    Real Valladolid         Spain   \n",
       "\n",
       "      birthday  height  weight              position  games  victories  ties  \\\n",
       "0   31.08.1983   177.0    72.0  Attacking Midfielder      1          0     0   \n",
       "1   08.01.1982   179.0    82.0          Right Winger      1          0     0   \n",
       "2   17.12.1992   181.0    79.0                   NaN      1          0     1   \n",
       "3   31.08.1993   191.0    87.0           Center Back      1          1     0   \n",
       "4   18.07.1991   172.0    70.0      Right Midfielder      1          1     0   \n",
       "5   08.11.1979   182.0    71.0           Center Back      1          0     0   \n",
       "6   10.11.1985   187.0    80.0         Left Fullback      1          1     0   \n",
       "7   04.04.1986   180.0    68.0  Defensive Midfielder      1          0     0   \n",
       "8   13.04.1984   193.0    80.0            Goalkeeper      1          0     1   \n",
       "9   13.03.1987   180.0    70.0        Right Fullback      1          1     0   \n",
       "10  26.01.1984   177.0    74.0        Right Fullback      2          2     0   \n",
       "\n",
       "    defeats  goals  yellowCards  \n",
       "0         1      0            0  \n",
       "1         1      0            1  \n",
       "2         0      0            1  \n",
       "3         0      0            0  \n",
       "4         0      0            0  \n",
       "5         1      0            0  \n",
       "6         0      0            0  \n",
       "7         1      0            0  \n",
       "8         0      0            0  \n",
       "9         0      0            0  \n",
       "10        0      0            1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dyads.ix[:10, :14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yellowReds</th>\n",
       "      <th>redCards</th>\n",
       "      <th>photoID</th>\n",
       "      <th>rater1</th>\n",
       "      <th>rater2</th>\n",
       "      <th>refNum</th>\n",
       "      <th>refCountry</th>\n",
       "      <th>Alpha_3</th>\n",
       "      <th>meanIAT</th>\n",
       "      <th>nIAT</th>\n",
       "      <th>seIAT</th>\n",
       "      <th>meanExp</th>\n",
       "      <th>nExp</th>\n",
       "      <th>seExp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95212.jpg</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>GRC</td>\n",
       "      <td>0.326391</td>\n",
       "      <td>712.0</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.396000</td>\n",
       "      <td>750.0</td>\n",
       "      <td>0.002696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1663.jpg</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>0.203375</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.010875</td>\n",
       "      <td>-0.204082</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.061504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ESP</td>\n",
       "      <td>0.369894</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.588297</td>\n",
       "      <td>1897.0</td>\n",
       "      <td>0.001002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ESP</td>\n",
       "      <td>0.369894</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.588297</td>\n",
       "      <td>1897.0</td>\n",
       "      <td>0.001002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ESP</td>\n",
       "      <td>0.369894</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.588297</td>\n",
       "      <td>1897.0</td>\n",
       "      <td>0.001002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3868.jpg</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>LUX</td>\n",
       "      <td>0.325185</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.013752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47704.jpg</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>LUX</td>\n",
       "      <td>0.325185</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.013752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22356.jpg</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>LUX</td>\n",
       "      <td>0.325185</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.013752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16528.jpg</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>LUX</td>\n",
       "      <td>0.325185</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.013752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36499.jpg</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>LUX</td>\n",
       "      <td>0.325185</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.013752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59786.jpg</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>LUX</td>\n",
       "      <td>0.325185</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.013752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    yellowReds  redCards    photoID  rater1  rater2  refNum  refCountry  \\\n",
       "0            0         0  95212.jpg    0.25    0.50       1           1   \n",
       "1            0         0   1663.jpg    0.75    0.75       2           2   \n",
       "2            0         0        NaN     NaN     NaN       3           3   \n",
       "3            0         0        NaN     NaN     NaN       3           3   \n",
       "4            0         0        NaN     NaN     NaN       3           3   \n",
       "5            0         0   3868.jpg    0.25    0.00       4           4   \n",
       "6            0         0  47704.jpg    0.00    0.25       4           4   \n",
       "7            0         0  22356.jpg    1.00    1.00       4           4   \n",
       "8            0         0  16528.jpg    0.25    0.25       4           4   \n",
       "9            0         0  36499.jpg    0.00    0.00       4           4   \n",
       "10           0         0  59786.jpg    0.00    0.00       4           4   \n",
       "\n",
       "   Alpha_3   meanIAT    nIAT     seIAT   meanExp    nExp     seExp  \n",
       "0      GRC  0.326391   712.0  0.000564  0.396000   750.0  0.002696  \n",
       "1      ZMB  0.203375    40.0  0.010875 -0.204082    49.0  0.061504  \n",
       "2      ESP  0.369894  1785.0  0.000229  0.588297  1897.0  0.001002  \n",
       "3      ESP  0.369894  1785.0  0.000229  0.588297  1897.0  0.001002  \n",
       "4      ESP  0.369894  1785.0  0.000229  0.588297  1897.0  0.001002  \n",
       "5      LUX  0.325185   127.0  0.003297  0.538462   130.0  0.013752  \n",
       "6      LUX  0.325185   127.0  0.003297  0.538462   130.0  0.013752  \n",
       "7      LUX  0.325185   127.0  0.003297  0.538462   130.0  0.013752  \n",
       "8      LUX  0.325185   127.0  0.003297  0.538462   130.0  0.013752  \n",
       "9      LUX  0.325185   127.0  0.003297  0.538462   130.0  0.013752  \n",
       "10     LUX  0.325185   127.0  0.003297  0.538462   130.0  0.013752  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dyads.ix[:10, 14:28]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the visualization of the data and the ipython notebook which previously worked on the same dataset, we observed that each data entry is a dyad between a player and a referee. They all contain a player ID, a referee ID, their respective descriptors and some informations about the dyad itself.\n",
    "\n",
    "We could define a dyad as a relationship between a player and a referee. A dyad can contain multiple encounters of the pair (player <-> referee) from different matches. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning (1)\n",
    "\n",
    "First of all, as we have (player,referee) dyads, a referee in our dataset should have arbitrated at least one match. This implies that we should find at least 22 dyads containing the given referee (a team has 11 players).\n",
    "We thus check that for each referee we obtain at least 22 dyads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of refs: 3147\n",
      "Number of refs with missing data: 2149\n",
      "Quantity of refs with missing data: 68.28725770575151%\n"
     ]
    }
   ],
   "source": [
    "referees = pd.DataFrame(dyads.groupby(['refNum']).size())\n",
    "referees.columns = ['count']\n",
    "bad_refs = referees[referees['count'] < 22]\n",
    "nb_refs = len(referees)\n",
    "nb_badrefs = len(bad_refs)\n",
    "print(\"Number of refs: \"+ str(nb_refs))\n",
    "print(\"Number of refs with missing data: \"+str(nb_badrefs))\n",
    "print(\"Quantity of refs with missing data: \" + str(100*(nb_badrefs/nb_refs)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found 2149 referees contained in less than 22 dyads. We can consider these as missing data events. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dyads: 146028\n",
      "Number of dyads after deletions: 143879\n",
      "Percent of dyads lost: 1.4716355767387057%\n"
     ]
    }
   ],
   "source": [
    "to_rm = bad_refs.index\n",
    "\n",
    "dyads_w_rm = dyads.drop(to_rm)\n",
    "nb_dyads = len(dyads)\n",
    "nb_dyads_wrm = len(dyads_w_rm)\n",
    "print(\"Number of dyads: \"+ str(len(dyads)))\n",
    "print(\"Number of dyads after deletions: \"+str(nb_dyads_wrm))\n",
    "print(\"Percent of dyads lost: \"+str(100*(1-(nb_dyads_wrm/nb_dyads)))+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that even that the referees to delete represented 68% of the set of referees, the percentage of lost dyads after a potential removal is only around 1.5%. We thus decide to apply the deletion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dyads = dyads.drop(to_rm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting of model's Target\n",
    "\n",
    "Our goal is to define if a player has dark skin or light skin. We thus need to design a model and train it on a part of this data with predefined skin labels. We will take the columns 'rater1' and 'rater2' to define this label. As the model needs an output (a valid skin label) we need at least one of these columns to be valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dyads = dyads[~(np.isnan(dyads['rater1']) & np.isnan(dyads['rater2']))]\n",
    "dyads.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As the label is defined by two columns we want these columns to agree with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_diff = (dyads['rater1']-dyads['rater2']).max()\n",
    "max_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.25,  1.  ,  0.5 ,  0.  ,  0.75])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dyads['rater1'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scale is going from 0 to 1 with a step of 0.25 and the max difference is 0.25.\n",
    "Therefore we cannot find a case where there are opposite opinions about a player (one black, the other white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose to transform this scale of rating into binary labels. We consider our model to predict more of a white/coloured ouput. \n",
    "\n",
    "First approach would be to take the mean of these values and if the result is smaller than 0.5 we want to output 0 ('white') and if it is greater than 0.5 output 1 ('black/coloured').\n",
    "\n",
    "Beforehand, it is important to check if both values are equal to 0.5. Indeed, this method won't be able to set a label to the given entry. We thus check if our dataset contains such values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8837"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dyads[(dyads['rater1'] == 0.5) & (dyads['rater2'] == 0.5)]['playerShort'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find 8989 cases where both raters find 0.5 as rating. We decide that those players will be represented by a 1 ('black')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dyads['y'] = (dyads['rater1'] + dyads['rater2']) / 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dyads.loc[dyads['y'] < 0.5, 'y'] = 0\n",
    "dyads.loc[dyads['y'] >= 0.5, 'y'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want a model that classifies players based on their descriptions, we first need to transform our data into a frame with an entry per player. Therefore, this implies, aggregating the dyads players while applying different aggregation functions per columns based on the information it contains. We will thus need to make some choices of interpretation to do the latter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating and cleaning (2)\n",
    "We first aggregate the dyads by players while appending their column informations into arrays. We also need  to not reorder the arrays to keep a mapping between a referee and its informations concerning the player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "players = dyads.groupby(['playerShort'])\n",
    "players = pprh.groups_to_lists(players, 'playerShort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "naive_data = pprh.drop_columns(players,['birthday', 'player', 'photoID', 'Alpha_3', 'refCountry', 'nIAT', 'nExp','index', 'refNum', 'rater1', 'rater2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a repetition of values for some columns that are supposed to be constant: \n",
    "weight, height, club, y (skin rate). We check if the respective lists of those columns per player contain the same value or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(pprh.has_same_value(naive_data['height']))\n",
    "print(pprh.has_same_value(naive_data['weight']))\n",
    "print(pprh.has_same_value(naive_data['y']))\n",
    "print(pprh.has_same_value(naive_data['club']))\n",
    "print(pprh.has_same_value(naive_data['leagueCountry']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, height and weight can differ for a given player. Is it because the list contains NaN or just different values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(pprh.has_nan(naive_data['height']))\n",
    "print(pprh.has_nan(naive_data['weight']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are NaNs in the height and weight columns for some players. We will replace those by their correct height and weight if we have them in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "naive_data['height'] = pprh.replace_nan(naive_data['height'])\n",
    "naive_data['weight'] = pprh.replace_nan(naive_data['weight'])\n",
    "\n",
    "print(pprh.has_nan(naive_data['height']))\n",
    "print(pprh.has_nan(naive_data['weight']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's check if the value is the same in the list for each player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(pprh.has_same_value(naive_data['height']))\n",
    "print(pprh.has_same_value(naive_data['weight']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if one of our player has no height or weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_height = pd.DataFrame(naive_data['height'].apply(lambda row: len(set(row))))\n",
    "player_nan_height = unique_height[unique_height['height']==0]\n",
    "unique_weight = pd.DataFrame(naive_data['weight'].apply(lambda row: len(set(row))))\n",
    "player_nan_weight = unique_weight[unique_weight['weight']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop them !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_diff = set(list(player_nan_weight.index.values) + list(player_nan_height.index.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "naive_data = naive_data.drop(list_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like no... So for each player let's take the mean of its height and weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(pprh.has_same_value(naive_data['height']))\n",
    "print(pprh.has_same_value(naive_data['weight']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing\n",
    "We apply different aggregation functions on our columns:\n",
    "- As discussed, the columns  club, leagueCountry, height and weight are constants. We only take the first element of the array. This is also the case for y since a player do not change skin color over time.\n",
    "- Since the player's position may change over time, we decide to apply a majority vote on the list of his positions. We also create a \"Unknown\" position class for the Na cases.\n",
    "- The columns games, victories, ties, defeats, goals, yellowCards, redCards and yellowReds are simply summed.\n",
    "- seIAT and seExp becomes the standard deviation of the meanIAT and meanExp a player has.\n",
    "- We take the average of meanIAT and meanExp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>club</th>\n",
       "      <th>defeats</th>\n",
       "      <th>games</th>\n",
       "      <th>goals</th>\n",
       "      <th>height</th>\n",
       "      <th>leagueCountry</th>\n",
       "      <th>meanExp</th>\n",
       "      <th>meanIAT</th>\n",
       "      <th>position</th>\n",
       "      <th>redCards</th>\n",
       "      <th>seExp</th>\n",
       "      <th>seIAT</th>\n",
       "      <th>ties</th>\n",
       "      <th>victories</th>\n",
       "      <th>weight</th>\n",
       "      <th>y</th>\n",
       "      <th>yellowCards</th>\n",
       "      <th>yellowReds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>playerShort</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aaron-hughes</th>\n",
       "      <td>Fulham FC</td>\n",
       "      <td>222</td>\n",
       "      <td>627</td>\n",
       "      <td>9</td>\n",
       "      <td>182.0</td>\n",
       "      <td>England</td>\n",
       "      <td>0.495149</td>\n",
       "      <td>0.346709</td>\n",
       "      <td>Center Back</td>\n",
       "      <td>0</td>\n",
       "      <td>0.231539</td>\n",
       "      <td>0.031525</td>\n",
       "      <td>171</td>\n",
       "      <td>234</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaron-hunt</th>\n",
       "      <td>Werder Bremen</td>\n",
       "      <td>120</td>\n",
       "      <td>334</td>\n",
       "      <td>62</td>\n",
       "      <td>183.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0.448310</td>\n",
       "      <td>0.349060</td>\n",
       "      <td>Attacking Midfielder</td>\n",
       "      <td>1</td>\n",
       "      <td>0.173776</td>\n",
       "      <td>0.022303</td>\n",
       "      <td>73</td>\n",
       "      <td>141</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaron-lennon</th>\n",
       "      <td>Tottenham Hotspur</td>\n",
       "      <td>112</td>\n",
       "      <td>399</td>\n",
       "      <td>30</td>\n",
       "      <td>165.0</td>\n",
       "      <td>England</td>\n",
       "      <td>0.491392</td>\n",
       "      <td>0.346055</td>\n",
       "      <td>Right Midfielder</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225670</td>\n",
       "      <td>0.028481</td>\n",
       "      <td>96</td>\n",
       "      <td>191</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaron-ramsey</th>\n",
       "      <td>Arsenal FC</td>\n",
       "      <td>65</td>\n",
       "      <td>251</td>\n",
       "      <td>37</td>\n",
       "      <td>178.0</td>\n",
       "      <td>England</td>\n",
       "      <td>0.515506</td>\n",
       "      <td>0.346706</td>\n",
       "      <td>Center Midfielder</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250735</td>\n",
       "      <td>0.032627</td>\n",
       "      <td>42</td>\n",
       "      <td>144</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abdelhamid-el-kaoutari</th>\n",
       "      <td>Montpellier HSC</td>\n",
       "      <td>43</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>180.0</td>\n",
       "      <td>France</td>\n",
       "      <td>0.335587</td>\n",
       "      <td>0.331600</td>\n",
       "      <td>Center Back</td>\n",
       "      <td>2</td>\n",
       "      <td>0.238918</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     club  defeats  games  goals  height  \\\n",
       "playerShort                                                                \n",
       "aaron-hughes                    Fulham FC      222    627      9   182.0   \n",
       "aaron-hunt                  Werder Bremen      120    334     62   183.0   \n",
       "aaron-lennon            Tottenham Hotspur      112    399     30   165.0   \n",
       "aaron-ramsey                   Arsenal FC       65    251     37   178.0   \n",
       "abdelhamid-el-kaoutari    Montpellier HSC       43    124      1   180.0   \n",
       "\n",
       "                       leagueCountry   meanExp   meanIAT  \\\n",
       "playerShort                                                \n",
       "aaron-hughes                 England  0.495149  0.346709   \n",
       "aaron-hunt                   Germany  0.448310  0.349060   \n",
       "aaron-lennon                 England  0.491392  0.346055   \n",
       "aaron-ramsey                 England  0.515506  0.346706   \n",
       "abdelhamid-el-kaoutari        France  0.335587  0.331600   \n",
       "\n",
       "                                    position  redCards     seExp     seIAT  \\\n",
       "playerShort                                                                  \n",
       "aaron-hughes                     Center Back         0  0.231539  0.031525   \n",
       "aaron-hunt              Attacking Midfielder         1  0.173776  0.022303   \n",
       "aaron-lennon                Right Midfielder         0  0.225670  0.028481   \n",
       "aaron-ramsey               Center Midfielder         1  0.250735  0.032627   \n",
       "abdelhamid-el-kaoutari           Center Back         2  0.238918  0.045100   \n",
       "\n",
       "                        ties  victories  weight  y  yellowCards  yellowReds  \n",
       "playerShort                                                                  \n",
       "aaron-hughes             171        234    71.0  0           19           0  \n",
       "aaron-hunt                73        141    73.0  0           42           0  \n",
       "aaron-lennon              96        191    63.0  0           10           0  \n",
       "aaron-ramsey              42        144    76.0  0           31           0  \n",
       "abdelhamid-el-kaoutari    40         41    73.0  0            8           4  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_data['y'] = naive_data['y'].apply(lambda x: int(x[0]))\n",
    "naive_data['club'] = naive_data['club'].apply(lambda x: x[0])\n",
    "naive_data['leagueCountry'] = naive_data['leagueCountry'].apply(lambda x: x[0])\n",
    "naive_data['height'] = naive_data['height'].apply(lambda x: x[0])\n",
    "naive_data['weight'] = naive_data['weight'].apply(lambda x: x[0])\n",
    "#majority vote\n",
    "naive_data['position'] = naive_data['position'].apply(mode)\n",
    "naive_data['position'].fillna(\"Unknown\", inplace=True)\n",
    "naive_data['games'] = naive_data['games'].apply(lambda x: sum(x))\n",
    "naive_data['victories'] = naive_data['victories'].apply(lambda x: sum(x))\n",
    "naive_data['ties'] = naive_data['ties'].apply(lambda x: sum(x))\n",
    "naive_data['defeats'] = naive_data['defeats'].apply(lambda x: sum(x))\n",
    "naive_data['goals'] = naive_data['goals'].apply(lambda x: sum(x))\n",
    "naive_data['yellowCards'] = naive_data['yellowCards'].apply(lambda x: sum(x))\n",
    "naive_data['yellowReds'] = naive_data['yellowReds'].apply(lambda x: sum(x))\n",
    "naive_data['redCards'] = naive_data['redCards'].apply(lambda x: sum(x))\n",
    "naive_data['seIAT'] = naive_data['meanIAT'].apply(np.std)\n",
    "naive_data['seExp'] = naive_data['meanExp'].apply(np.std)\n",
    "naive_data['meanIAT'] = naive_data['meanIAT'].apply(np.mean)\n",
    "naive_data['meanExp'] = naive_data['meanExp'].apply(np.mean)\n",
    "naive_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training our classifier, we drop our nan in height and weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "naive_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = naive_data.pop('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We encode our categorical data columns. The columns club, leagueCountry and position are supposed to be categorical data. We could dummily encode them with indices as scikit's label_encoding does. However, sklearn's RandomForestClassifier consider those values as continuous. At a given branch, it will separate the obtained values through intervals making the distance between indices important.\n",
    "Therefore we decide to one-hot encode our data. It slightly increases our feature dimensions but will reduce our bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_encode = ['club', 'leagueCountry','position']\n",
    "encoded_data = pprh.one_hot_encode(naive_data, to_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier: check this out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classic score\n",
      "0.778156996587\n",
      "Cross-val score\n",
      "0.791485920852\n"
     ]
    }
   ],
   "source": [
    "#CV then score (=prediction)\n",
    "X_train, X_test, y_train, y_test = train_test_split(encoded_data, labels, test_size=0.20, random_state=0)\n",
    "rfclf = RandomForestClassifier(n_estimators=10).fit(X_train, y_train) \n",
    "score = rfclf.score(X_test, y_test)\n",
    "print(\"Classic score\")\n",
    "print(score)\n",
    "\n",
    "#Classifier then CV K-Fold (k=3, default)\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "scores = cross_val_score(clf, encoded_data, labels, cv=20)\n",
    "print(\"Cross-val score\")\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we got a score around 78% but we know that we are losing informations on the cards given by different referees. It means that for a player the value of a card given by a \"racist\" referee is the same as the value of a card given by a \"not racist\" referee. We don't want to lose this information, so we will need to ponder the cards using the \"racist\" value given for a referee."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we normalize the value of meanIAT and meanEXP in our dyads dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm_dyads = pd.DataFrame(dyads)\n",
    "norm_dyads['meanIATNorm'] = (norm_dyads['meanIAT'] - norm_dyads['meanIAT'].min()) / (norm_dyads['meanIAT'].max() - norm_dyads['meanIAT'].min())\n",
    "norm_dyads['meanExpNorm'] = (norm_dyads['meanExp'] - norm_dyads['meanExp'].min()) / (norm_dyads['meanExp'].max() - norm_dyads['meanExp'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm_dyads['refScore']=(norm_dyads['meanIAT']+norm_dyads['meanExp'])/2\n",
    "norm_dyads['yellowCardsPonder']=norm_dyads['refScore'] * norm_dyads['yellowCards']\n",
    "norm_dyads['redCardsPonder']=norm_dyads['refScore'] * norm_dyads['redCards']\n",
    "norm_dyads['yellowRedsPonder']=norm_dyads['refScore'] * norm_dyads['yellowReds']\n",
    "norm_dyads.drop(['yellowCards', 'redCards', 'yellowReds'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same changes as above on the new dyad data.TODO: reformulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "players_norm = aggr.from_dyads_to_players_aggregate(norm_dyads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "players_norm.drop(['meanIATNorm', 'meanExpNorm'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_norm = players_norm.pop('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_encode_norm = ['club', 'leagueCountry','position']\n",
    "#encoded_data_norm = pprh.label_encode(players_norm, to_encode_norm)\n",
    "encoded_data_norm = pprh.one_hot_encode(players_norm, to_encode_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-val score\n",
      "0.79070804092\n"
     ]
    }
   ],
   "source": [
    "#Classifier then CV K-Fold (k=3, default)\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "scores = cross_val_score(clf, encoded_data_norm, labels_norm, cv=8)\n",
    "print(\"Cross-val score\")\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have satisfying data preprocessing and classification. We will look at the influence of the features on our model. In other words, we will measure the feature importances as well as the model behaviour in the case of feature modifications (mainly deletion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Feature Importances\n",
    "(values, labels) = clfh.plot_importances(clf, encoded_data_norm, labels_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remark that the features that often comes at the top of our plot are the two standard deviation of IAT and Exp and also their mean value. Let's now tweak our data by removing/encoding/adding some columns and see if we can get different important features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first try to not encode the column using Hot Encoder but just using Label Encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_encoded_data_norm = pprh.label_encode(players_norm, to_encode_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-val score\n",
      "0.788684968957\n"
     ]
    }
   ],
   "source": [
    "#Classifier then CV K-Fold (k=3, default)\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "scores = cross_val_score(clf, label_encoded_data_norm, labels_norm, cv=8)\n",
    "print(\"Cross-val score\")\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Feature Importances\n",
    "(values, labels) = clfh.plot_importances(clf, label_encoded_data_norm, labels_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Unsupervised Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
