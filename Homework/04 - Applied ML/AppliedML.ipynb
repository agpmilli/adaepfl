{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Applied ML\n",
    "\n",
    "## Deadline\n",
    "Monday November 21, 2016 at 11:59PM\n",
    "\n",
    "## Important Notes\n",
    "* Make sure you push on GitHub your Notebook with all the cells already evaluated\n",
    "* Don't forget to add a textual description of your thought process, the assumptions you made, and the solution\n",
    "you plan to implement!\n",
    "* Please write all your comments in English, and use meaningful variable names in your code\n",
    "\n",
    "## Background\n",
    "In this homework we will gain experience on Applied Machine Learning, exploring an interesting dataset about soccer players and referees.\n",
    "You can find all the data in the `CrowdstormingDataJuly1st.csv` file, while you can read a thorough [dataset description here](DATA.md).\n",
    "Given that the focus of this homework is Machine Learning, I recommend you to first take a look at [this notebook](http://nbviewer.jupyter.org/github/mathewzilla/redcard/blob/master/Crowdstorming_visualisation.ipynb)\n",
    "containing a solid work in pre-processing + visualization of the given dataset. You are *not* allowed to just copy/paste the pre-processing steps\n",
    "performed by the notebook authors -- you are still supposed to perform your own data analysis for the homework. Still, I'm confident that consulting first\n",
    "the work done by expert data analysts will speed up tangibly your effort (i.e., they have already found for you many glitches in the data :)\n",
    "\n",
    "\n",
    "## Assignment\n",
    "1. Train a `sklearn.ensemble.RandomForestClassifier` that given a soccer player description outputs his skin color. Show how different parameters \n",
    "passed to the Classifier affect the overfitting issue. Perform cross-validation to mitigate the overfitting of your model. Once you assessed your model,\n",
    "inspect the `feature_importances_` attribute and discuss the obtained results. With different assumptions on the data (e.g., dropping certain features even\n",
    "before feeding them to the classifier), can you obtain a substantially different `feature_importances_` attribute?\n",
    "*BONUS*: plot the learning curves against at least 2 different sets of parameters passed to your Random Forest. To obtain smooth curves, partition\n",
    "your data in at least 20 folds. Can you find a set of parameters that leads to high bias, and one which does not?\n",
    "\n",
    "2. Aggregate the referee information grouping by soccer player, and use an unsupervised learning technique to cluster the soccer players in 2 disjoint\n",
    "clusters. Remove features iteratively, and at each step perform again the clustering and compute the silhouette score -- can you find a configuration of features with high silhouette\n",
    "score where players with dark and light skin colors belong to different clusters? Discuss the obtained results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------\n",
    "# Data Description\n",
    "\n",
    "From a company for sports statistics, we obtained data and profile photos from all soccer players (N = 2053) playing in the first male divisions of England, Germany, France and Spain in the 2012-2013 season and all referees (N = 3147) that these players played under in their professional career. We created a dataset of player–referee dyads including the number of matches players and referees encountered each other and our dependent variable, the number of red cards given to a player by a particular referee throughout all matches the two encountered each other.\n",
    " \n",
    "Player photos were available from the source for 1586 out of 2053 players. Players’ skin tone was coded by two independent raters blind to the research question who, based on their profile photo, categorized players on a 5-point scale ranging from “very light skin” to “very dark skin” with “neither dark nor light skin” as the center value. \n",
    "\n",
    "Additionally, implicit bias scores for each referee country were calculated using a race implicit association test (IAT), with higher values corresponding to faster white | good, black | bad associations. Explicit bias scores for each referee country were calculated using a racial thermometer task, with higher values corresponding to greater feelings of warmth toward whites versus blacks. Both these measures were created by aggregating data from many online users in referee countries taking these tests on [Project Implicit](http://projectimplicit.net).\n",
    "\n",
    "In all, the dataset has a total of 146028 dyads of players and referees. A detailed description of all variables in the dataset can be seen in the list below.\n",
    "\n",
    "## Variables:\n",
    "\n",
    "*playerShort* - short player ID\n",
    "\n",
    "*player* - player name\n",
    "\n",
    "*club* - player club\n",
    "\n",
    "*leagueCountry* - country of player club (England, Germany, France, and Spain)\n",
    "\n",
    "*birthday* - player birthday\n",
    "\n",
    "*height* - player height (in cm)\n",
    "\n",
    "*weight* - player weight (in kg)\n",
    "\n",
    "*position* - detailed player position\n",
    "\n",
    "*games* - number of games in the player-referee dyad\n",
    "\n",
    "*victories* - victories in the player-referee dyad\n",
    "\n",
    "*ties* - ties in the player-referee dyad\n",
    "\n",
    "*defeats* - losses in the player-referee dyad\n",
    "\n",
    "*goals* - goals scored by a player in the player-referee dyad\n",
    "\n",
    "*yellowCards* - number of yellow cards player received from referee\n",
    "\n",
    "*yellowReds* - number of yellow-red cards player received from referee\n",
    "\n",
    "*redCards* - number of red cards player received from referee\n",
    "\n",
    "*photoID* - ID of player photo (if available)\n",
    "\n",
    "*rater1* - skin rating of photo by rater 1 (5-point scale ranging from “very light skin” to “very dark skin”)\n",
    "\n",
    "*rater2* - skin rating of photo by rater 2 (5-point scale ranging from “very light skin” to “very dark skin”)\n",
    "\n",
    "*refNum* - unique referee ID number (referee name removed for anonymizing purposes)\n",
    "\n",
    "*refCountry* - unique referee country ID number (country name removed for anonymizing purposes)\n",
    "\n",
    "*meanIAT* - mean implicit bias score (using the race IAT) for referee country, higher values correspond to faster white | good, black | bad associations\n",
    "\n",
    "*nIAT* - sample size for race IAT in that particular country\n",
    "\n",
    "*seIAT* - standard error for mean estimate of race IAT\n",
    "\n",
    "*meanExp* - mean explicit bias score (using a racial thermometer task) for referee country, higher values correspond to greater feelings of warmth toward whites versus blacks\n",
    "\n",
    "*nExp* - sample size for explicit bias in that particular country\n",
    "\n",
    "*seExp* - standard error for mean estimate of explicit bias measure\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# IMPLEMENTATION\n",
    "## Supervised Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import metrics\n",
    "import preprocessing_helper as preproc_helper\n",
    "import classifiers_helper as class_helper\n",
    "import aggregater_helper as aggr_helper\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = 'CrowdstormingDataJuly1st.csv'\n",
    "dyads = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Visualization of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dyads.ix[:5, :int(len(dyads.columns) / 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dyads.ix[:5, 14:len(dyads.columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the visualization of the data and the ipython notebook which previously worked on the same dataset, we observed that each data entry is a dyad between a player and a referee. They all contain a player ID, a referee ID, their respective descriptors and some informations about the dyad itself.\n",
    "\n",
    "We could define a dyad as a relationship between a player and a referee. A dyad can contain multiple encounters of the pair (player <-> referee) from different matches. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cleaning \n",
    "\n",
    "First of all, as we have (player <-> referee) dyads, a referee in our dataset should have arbitrated at least one match. This implies that we should find at least 22 dyads containing the given referee (a team has 11 players).\n",
    "We thus check that for each referee we obtain at least 22 dyads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "referees = pd.DataFrame(dyads.groupby(['refNum']).size())\n",
    "referees.columns = ['count']\n",
    "bad_refs = referees[referees['count'] < 22]\n",
    "nb_refs = len(referees)\n",
    "nb_badrefs = len(bad_refs)\n",
    "print(\"Total number of refs:\", nb_refs)\n",
    "print(\"Number of refs with missing data:\", nb_badrefs)\n",
    "print(\"Percentage of refs with missing data:\", 100 * (nb_badrefs / nb_refs), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found 2149 referees contained in less than 22 dyads. We can consider these as missing data events. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dyads_w_rm = dyads.drop(bad_refs.index)\n",
    "nb_dyads = len(dyads)\n",
    "nb_dyads_wrm = len(dyads_w_rm)\n",
    "print(\"Number of dyads:\", nb_dyads)\n",
    "print(\"Number of dyads after deletions:\", nb_dyads_wrm)\n",
    "print(\"Percent of dyads lost:\", (100 * (1 - (nb_dyads_wrm / nb_dyads))),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that even that the referees to delete represented 68% of the set of referees, the percentage of lost dyads after a potential removal is only around 1.5%. We thus decide to apply the deletion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dyads = dyads.drop(bad_refs.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Defining the label\n",
    "\n",
    "Our goal is to define if a player has dark skin or light skin. We thus need to design a model and train it on a part of this data with predefined skin labels. We will take the columns 'rater1' and 'rater2' to define this label. As the model needs an output (a valid skin label) we need at least one of these columns to be valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dyads = dyads[~(np.isnan(dyads['rater1']) & np.isnan(dyads['rater2']))]\n",
    "dyads.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As we have two observations defining the skin's color for each player, we want to aggregate them but first we have to check if there exists disparities between them. We also check what are the different values given by each rater."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"The max difference between two raters is\", (dyads['rater1']-dyads['rater2']).max())\n",
    "print(\"Rating values given by rater 1\", dyads['rater1'].unique())\n",
    "print(\"Rating values given by rater 2\", dyads['rater2'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scale is going from 0 to 1 with a step of 0.25 and the max difference is 0.25.\n",
    "Therefore we cannot find a case where there are opposite opinions about a player (one black, the other white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose to transform this scale of rating into binary labels. We consider our model to predict more of a white/coloured ouput. We choose to take the mean of these values and if the result is smaller than 0.5 we want to output 0 ('white') and if it is greater than 0.5 output 1 ('black/coloured')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dyads['y'] = (dyads['rater1'] + dyads['rater2']) / 2 \n",
    "dyads.loc[dyads['y'] < 0.5, 'y'] = 0\n",
    "dyads.loc[dyads['y'] >= 0.5, 'y'] = 1\n",
    "dyads.drop(['rater1', 'rater2'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training the classifier - Round one\n",
    "Now that we have clean the data, we can try to create a classifier on it and train it. We first pop the labels, then before label encoding the object columns in the original dataframe, we fill them first with the string 'Unknown' if we encounter a NaN value.\n",
    "\n",
    "Once the object columns are label encoded, we still fill the NaN values with -999. This is an arbitrary value we choose, since every column should not contain a negative value, it behaves as if it was not known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dyads_encoded = dyads.copy()\n",
    "dyads_encoded['position'].fillna('Unknown', inplace=True)\n",
    "dyads_encoded['Alpha_3'].fillna('Unknown', inplace=True)\n",
    "labels = dyads_encoded.pop('y')\n",
    "dyads_encoded = preproc_helper.label_encode(dyads_encoded, list(dyads_encoded.select_dtypes(include=['object']).columns))\n",
    "dyads_encoded.fillna(-999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=10)\n",
    "scores = cross_val_score(classifier, dyads_encoded, labels, cv=20)\n",
    "print(\"Cross-val score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier score is impressive. Let's look at the important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Feature Importances\n",
    "class_helper.plot_importances(classifier, dyads_encoded, labels, 0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something is going wrong (why photoID should be an important feature?). Since we train our model with the dyads it means that a same player can be in the train and in the test dataset at the same time, so indeed it's logical that the classifier uses the player name and its unique related informations (birthday, photoID, playerShort) to classify.\n",
    "\n",
    "As such the model does not make sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training the classifier - Round two\n",
    "\n",
    "As seen before the model does not make sense. Hence we move to an approach where we transform our data into a frame with an entry per player. Therefore, this implies, aggregating the dyads players while applying different aggregation functions per columns based on the information it contains. We will thus need to make some choices of interpretation to do the latter.\n",
    "\n",
    "#### 4.1 Aggregating and cleaning the data\n",
    "\n",
    "We first aggregate the dyads by players while appending their column informations into arrays. We also need  to not reorder the arrays to keep a mapping between a referee and its informations concerning the player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "players = dyads.groupby(['playerShort'])\n",
    "players = preproc_helper.groups_to_lists(players, 'playerShort')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the important features above, some of the columns are unique and represents directly a player. It means that they won't help to classify them. So we decide to drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "players = players.drop(['birthday', 'player', 'photoID', 'Alpha_3', 'refCountry','index', 'refNum', 'nIAT', 'nExp'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a repetition of values for some columns that are supposed to be constant: \n",
    "weight, height, club. We check if the respective lists of those columns per player contain the same value or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for column in ['height', 'weight', 'y', 'club', 'leagueCountry']:\n",
    "    print(column, ':', preproc_helper.has_same_value(players[column]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, height and weight can differ for a given player. We check where it's the case and if all the values are NaN for these records (if it's the case it means we cannot deduce a height or a weight based on other observations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "players_without_height_or_weight = set()\n",
    "for column in ['height', 'weight']:\n",
    "    print('\\n', column.upper())\n",
    "    for index, item in players[column].iteritems():\n",
    "        unique_values = set(item)\n",
    "        if(len(unique_values) > 1):\n",
    "            print(index, all(np.isnan(x) for x in unique_values))\n",
    "            players_without_height_or_weight.add(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hence drop the players that have no datas for their height or their weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "players = players.drop(players_without_height_or_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now they all have the same value so we will represent it by the first element of each list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Reducing\n",
    "We apply different aggregation functions on our columns:\n",
    "- As discussed, the columns  club, leagueCountry, height and weight are constants. We only take the first element of the array. This is also the case for y since a player do not change skin color over time.\n",
    "- Since the player's position may change over time, we decide to apply a majority vote on the list of his positions. We also create a \"Unknown\" position class for the Na cases.\n",
    "- The columns games, victories, ties, defeats, goals, yellowCards, redCards and yellowReds are simply summed.\n",
    "- seIAT and seExp becomes the standard deviation of the meanIAT and meanExp a player has.\n",
    "- We take the average of meanIAT and meanExp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aggregating_functions = [\n",
    "    (['y'], lambda x: int(x[0])), \n",
    "    (['club', 'leagueCountry', 'height', 'weight'], lambda x: x[0]),\n",
    "    (['position'], mode),\n",
    "    (['games', 'victories', 'ties', 'defeats', 'goals', 'yellowCards', 'yellowReds', 'redCards'], sum),\n",
    "    ([('seIAT', 'meanIAT'), ('seExp', 'meanExp')], np.std),\n",
    "    (['meanIAT', 'meanExp'], np.mean)\n",
    "]\n",
    "players = aggr_helper.aggregate_dyads_to_players(players, aggregating_functions)\n",
    "players.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training our classifier, we drop the last NaNs and we pop the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "players.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = players.pop('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We encode our categorical data columns. The columns club, leagueCountry and position are supposed to be categorical data. We could dummily encode them with indices as scikit's label_encoding does. However, sklearn's RandomForestClassifier consider those values as continuous. At a given branch, it will separate the obtained values through intervals making the distance between indices important.\n",
    "Therefore we decide to one-hot encode our data. It slightly increases our feature dimensions but will reduce our bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoded_player_data = preproc_helper.label_encode(players, list(players.select_dtypes(include=['object']).columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know create our random classifier and train it using a 20-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "scores = cross_val_score(clf, encoded_player_data, labels, cv=20)\n",
    "\n",
    "print(\"Cross-val score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we got a score around 79% (that makes more sense) but we know that we are losing informations on the cards given by different referees. It means that for a player the value of a card given by a \"racist\" referee is the same as the value of a card given by a \"not racist\" referee. We don't want to lose this information, so we will need to ponder the cards using the \"racist\" value given for a referee."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Ponderation of cards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we normalize the value of meanIAT and meanEXP in our dyads dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm_dyads = dyads.copy()\n",
    "norm_dyads['meanIATNorm'] = (norm_dyads['meanIAT'] - norm_dyads['meanIAT'].min()) / (norm_dyads['meanIAT'].max() - norm_dyads['meanIAT'].min())\n",
    "norm_dyads['meanExpNorm'] = (norm_dyads['meanExp'] - norm_dyads['meanExp'].min()) / (norm_dyads['meanExp'].max() - norm_dyads['meanExp'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have that, we create for each dyad a referee score and 3 new columns that ponders the value of the card (yellow/red/yellowRed) given by the referee score for that match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm_dyads['refScore'] = (norm_dyads['meanIATNorm'] + norm_dyads['meanExpNorm']) / 2\n",
    "norm_dyads['yellowCardsPonder'] = norm_dyads['refScore'] * norm_dyads['yellowCards']\n",
    "norm_dyads['redCardsPonder'] = norm_dyads['refScore'] * norm_dyads['redCards']\n",
    "norm_dyads['yellowRedsPonder'] = norm_dyads['refScore'] * norm_dyads['yellowReds']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before we aggregate this dyad data to get an entry per player. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm_dyads = norm_dyads.groupby(['playerShort'])\n",
    "norm_dyads = preproc_helper.groups_to_lists(norm_dyads, 'playerShort')\n",
    "\n",
    "norm_dyads.drop(players_without_height_or_weight, inplace=True)\n",
    "norm_dyads.drop(['birthday', 'player', 'photoID', 'Alpha_3', 'refCountry', 'nIAT', 'nExp','index', 'refNum', 'meanIATNorm', 'meanExpNorm', 'refScore'], axis=1, inplace=True)\n",
    "\n",
    "aggregating_functions = [\n",
    "    (['y'], lambda x: int(x[0])), \n",
    "    (['club', 'leagueCountry', 'height', 'weight'], lambda x: x[0]),\n",
    "    (['position'], mode),\n",
    "    (['games', 'victories', 'ties', 'defeats', 'goals', 'yellowCards', 'yellowReds', 'redCards', 'yellowCardsPonder', 'yellowRedsPonder', 'redCardsPonder'], sum),\n",
    "    ([('seIAT', 'meanIAT'), ('seExp', 'meanExp')], np.std),\n",
    "    (['meanIAT', 'meanExp'], np.mean)\n",
    "]\n",
    "\n",
    "players_norm = aggr_helper.aggregate_dyads_to_players(norm_dyads, aggregating_functions)\n",
    "players_norm.dropna(inplace=True)\n",
    "\n",
    "players_norm_encoded = preproc_helper.one_hot_encode(players_norm, ['club', 'leagueCountry','position'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We now pop the labels from the dataframe and we build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_norm = players_norm_encoded.pop('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "scores = cross_val_score(clf, players_norm_encoded, labels_norm, cv=20)\n",
    "print(\"Cross-val score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Features Importance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have satisfying data preprocessing and classification. We will look at the influence of the features on our model. In other words, we will measure the feature importances as well as the model behaviour in the case of feature modifications (mainly deletion)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Features importance with hot encoded labels (club, league country and position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_helper.plot_importances(clf, players_norm_encoded, labels_norm, 0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remark that the features that often comes at the top of our plot are the two standard deviation of IAT and Exp and also their mean value. Let's now tweak our data by removing/encoding/adding some columns and see if we can get different important features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Features importance dropping encoded labels (club, league country and position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "players_norm_no_encoding = players_norm.drop(['club', 'leagueCountry','position'], axis=1)\n",
    "scores = cross_val_score(clf, players_norm_no_encoding, players_norm_no_encoding.pop('y'), cv=8)\n",
    "print(\"Cross-val score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_helper.plot_importances(clf, players_norm_no_encoding, labels_norm, 0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then try to not encode the column using Hot Encoder but just using Label Encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Features importance using Label Encoder (club, league country and position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_encoded_data_norm = preproc_helper.label_encode(players_norm, ['club', 'leagueCountry','position'])\n",
    "labels_norm = label_encoded_data_norm.pop('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(clf, label_encoded_data_norm, labels_norm, cv=20)\n",
    "print(\"Cross-val score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Feature Importances\n",
    "class_helper.plot_importances(clf, label_encoded_data_norm, labels_norm, 0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Features importance with only the characteristics of the player using Label Encoder\n",
    "Now we try to build a model where we only have the characteristics of the player itself and not the referee informations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_encoded_data_norm = preproc_helper.label_encode(players_norm, ['club', 'leagueCountry','position'])\n",
    "player_characteristics = label_encoded_data_norm.drop(['seIAT', 'meanIAT', 'meanExp', 'seExp', 'yellowCardsPonder', 'redCardsPonder', 'yellowRedsPonder'], axis=1)\n",
    "labels_norm = player_characteristics.pop('y')\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "scores = cross_val_score(clf, player_characteristics, labels_norm, cv=20)\n",
    "print(\"Cross-val score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_helper.plot_importances(clf, player_characteristics, labels_norm, 0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is less accurate but still surprisingly high. In this case the important features are different. It looks like the classifier uses the results of the matches (victories/ties/defeats) as its best features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the learning curves for the player characteristics and the dataset with all the columns (including the referee country IAT, Exp data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Feature Importances\n",
    "import plot_learning_curve as plc\n",
    "(X_train, X_test, y_train, y_test, values, labels) = class_helper.importances(clf, player_characteristics, labels_norm, 0.005)\n",
    "plc.plot_learning_curve(clf, 'Learning curves on player characteristics (RandomForestClassifier)',X_train, y_train, cv=20).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Feature Importances\n",
    "(X_train, X_test, y_train, y_test, values, labels) = class_helper.importances(clf, players_norm_encoded, labels_norm, 0.005)\n",
    "plc.plot_learning_curve(clf, 'Learning curve on all data (RandomForestClassifier)',X_train, y_train, cv=20).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bias in the first plot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Unsupervised Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We want to do a clustering of the soccer players into 2 different clusters. We thus need to transform the data into an aggregated form of it grouped by players. As we did the aggregation as well as some cleaning, we will directly reuse the df we obtained after those transformations.\n",
    "This implies that we use the same reducing functions as well. We also keep the new columns yellowCardsPonder,redCardsPonder and yellowRedsPonder.\n",
    "Of course, we take a version of the data without the label y containing the skin colour information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>club</th>\n",
       "      <th>defeats</th>\n",
       "      <th>games</th>\n",
       "      <th>goals</th>\n",
       "      <th>height</th>\n",
       "      <th>leagueCountry</th>\n",
       "      <th>meanExp</th>\n",
       "      <th>meanIAT</th>\n",
       "      <th>position</th>\n",
       "      <th>redCards</th>\n",
       "      <th>redCardsPonder</th>\n",
       "      <th>seExp</th>\n",
       "      <th>seIAT</th>\n",
       "      <th>ties</th>\n",
       "      <th>victories</th>\n",
       "      <th>weight</th>\n",
       "      <th>yellowCards</th>\n",
       "      <th>yellowCardsPonder</th>\n",
       "      <th>yellowReds</th>\n",
       "      <th>yellowRedsPonder</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>playerShort</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aaron-hughes</th>\n",
       "      <td>Fulham FC</td>\n",
       "      <td>222</td>\n",
       "      <td>627</td>\n",
       "      <td>9</td>\n",
       "      <td>182.0</td>\n",
       "      <td>England</td>\n",
       "      <td>0.495149</td>\n",
       "      <td>0.346709</td>\n",
       "      <td>Center Back</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231539</td>\n",
       "      <td>0.031525</td>\n",
       "      <td>171</td>\n",
       "      <td>234</td>\n",
       "      <td>71.0</td>\n",
       "      <td>19</td>\n",
       "      <td>7.325574</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaron-hunt</th>\n",
       "      <td>Werder Bremen</td>\n",
       "      <td>120</td>\n",
       "      <td>334</td>\n",
       "      <td>62</td>\n",
       "      <td>183.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0.448310</td>\n",
       "      <td>0.349060</td>\n",
       "      <td>Attacking Midfielder</td>\n",
       "      <td>1</td>\n",
       "      <td>0.336298</td>\n",
       "      <td>0.173776</td>\n",
       "      <td>0.022303</td>\n",
       "      <td>73</td>\n",
       "      <td>141</td>\n",
       "      <td>73.0</td>\n",
       "      <td>42</td>\n",
       "      <td>15.321594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaron-lennon</th>\n",
       "      <td>Tottenham Hotspur</td>\n",
       "      <td>112</td>\n",
       "      <td>399</td>\n",
       "      <td>30</td>\n",
       "      <td>165.0</td>\n",
       "      <td>England</td>\n",
       "      <td>0.491392</td>\n",
       "      <td>0.346055</td>\n",
       "      <td>Right Midfielder</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225670</td>\n",
       "      <td>0.028481</td>\n",
       "      <td>96</td>\n",
       "      <td>191</td>\n",
       "      <td>63.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3.696365</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaron-ramsey</th>\n",
       "      <td>Arsenal FC</td>\n",
       "      <td>65</td>\n",
       "      <td>251</td>\n",
       "      <td>37</td>\n",
       "      <td>178.0</td>\n",
       "      <td>England</td>\n",
       "      <td>0.515506</td>\n",
       "      <td>0.346706</td>\n",
       "      <td>Center Midfielder</td>\n",
       "      <td>1</td>\n",
       "      <td>0.335392</td>\n",
       "      <td>0.250735</td>\n",
       "      <td>0.032627</td>\n",
       "      <td>42</td>\n",
       "      <td>144</td>\n",
       "      <td>76.0</td>\n",
       "      <td>31</td>\n",
       "      <td>11.886911</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abdelhamid-el-kaoutari</th>\n",
       "      <td>Montpellier HSC</td>\n",
       "      <td>43</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>180.0</td>\n",
       "      <td>France</td>\n",
       "      <td>0.335587</td>\n",
       "      <td>0.331600</td>\n",
       "      <td>Center Back</td>\n",
       "      <td>2</td>\n",
       "      <td>0.670785</td>\n",
       "      <td>0.238918</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2.683139</td>\n",
       "      <td>4</td>\n",
       "      <td>1.405477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     club  defeats  games  goals  height  \\\n",
       "playerShort                                                                \n",
       "aaron-hughes                    Fulham FC      222    627      9   182.0   \n",
       "aaron-hunt                  Werder Bremen      120    334     62   183.0   \n",
       "aaron-lennon            Tottenham Hotspur      112    399     30   165.0   \n",
       "aaron-ramsey                   Arsenal FC       65    251     37   178.0   \n",
       "abdelhamid-el-kaoutari    Montpellier HSC       43    124      1   180.0   \n",
       "\n",
       "                       leagueCountry   meanExp   meanIAT  \\\n",
       "playerShort                                                \n",
       "aaron-hughes                 England  0.495149  0.346709   \n",
       "aaron-hunt                   Germany  0.448310  0.349060   \n",
       "aaron-lennon                 England  0.491392  0.346055   \n",
       "aaron-ramsey                 England  0.515506  0.346706   \n",
       "abdelhamid-el-kaoutari        France  0.335587  0.331600   \n",
       "\n",
       "                                    position  redCards  redCardsPonder  \\\n",
       "playerShort                                                              \n",
       "aaron-hughes                     Center Back         0        0.000000   \n",
       "aaron-hunt              Attacking Midfielder         1        0.336298   \n",
       "aaron-lennon                Right Midfielder         0        0.000000   \n",
       "aaron-ramsey               Center Midfielder         1        0.335392   \n",
       "abdelhamid-el-kaoutari           Center Back         2        0.670785   \n",
       "\n",
       "                           seExp     seIAT  ties  victories  weight  \\\n",
       "playerShort                                                           \n",
       "aaron-hughes            0.231539  0.031525   171        234    71.0   \n",
       "aaron-hunt              0.173776  0.022303    73        141    73.0   \n",
       "aaron-lennon            0.225670  0.028481    96        191    63.0   \n",
       "aaron-ramsey            0.250735  0.032627    42        144    76.0   \n",
       "abdelhamid-el-kaoutari  0.238918  0.045100    40         41    73.0   \n",
       "\n",
       "                        yellowCards  yellowCardsPonder  yellowReds  \\\n",
       "playerShort                                                          \n",
       "aaron-hughes                     19           7.325574           0   \n",
       "aaron-hunt                       42          15.321594           0   \n",
       "aaron-lennon                     10           3.696365           0   \n",
       "aaron-ramsey                     31          11.886911           0   \n",
       "abdelhamid-el-kaoutari            8           2.683139           4   \n",
       "\n",
       "                        yellowRedsPonder  \n",
       "playerShort                               \n",
       "aaron-hughes                    0.000000  \n",
       "aaron-hunt                      0.000000  \n",
       "aaron-lennon                    0.000000  \n",
       "aaron-ramsey                    0.000000  \n",
       "abdelhamid-el-kaoutari          1.405477  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions = players_norm.copy()\n",
    "gr_truth = labels.copy()\n",
    "whole = pd.concat([gr_truth,descriptions], axis=1)\n",
    "descriptions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now encode our label columns and then standardize all our features. This will remove some bias in our clustering models (even more so for K-Means for instance). It will equalize our feature variances thus preventing some features to have more weight during computation.\n",
    "For the sake of model selection, we will encode our our label columns using two different methods mainly one-hot and label encoding and then compare the obtained clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pprh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-b8009efeae28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Dummy Label Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdummy_descr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpprh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescriptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'leagueCountry'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'club'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdummy_descr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdummy_descr\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdummy_descr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdummy_descr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#One-hot Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pprh' is not defined"
     ]
    }
   ],
   "source": [
    "#Dummy Label Encoding\n",
    "dummy_descr = pprh.label_encode(descriptions.copy(), ['leagueCountry', 'club', 'position'])\n",
    "dummy_descr = (dummy_descr - dummy_descr.mean()) / dummy_descr.std()\n",
    "\n",
    "#One-hot Encoding\n",
    "onehot_descr = pprh.one_hot_encode(descriptions.copy(), ['leagueCountry', 'club', 'position'])\n",
    "onehot_descr = (onehot_descr - onehot_descr.mean()) / onehot_descr.std()\n",
    "\n",
    "\n",
    "dummy_descr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means\n",
    "\n",
    "We now computer a first clustering using K-Means with 2 clusters. We will evaluate our clusters using the silhouette score which outputs an score of the clustering quality in the range [-1;1] with 1 being a perfect clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dummy_descr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-27523f6c9a88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdummy_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_descr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdummy_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msilhouette_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_descr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dummy Encoding: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dummy_descr' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans \n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=1)\n",
    "dummy_labels = kmeans.fit(dummy_descr).labels_\n",
    "dummy_score = silhouette_score(dummy_descr, dummy_labels)\n",
    "print(\"Dummy Encoding: \"+str(dummy_score))\n",
    "loss1 = np.mean(np.absolute(np.subtract(dummy_labels, list(1-gr_truth))))\n",
    "print(\"0-1 Loss score:\" + str(loss1))\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "onehot_labels = kmeans.fit(onehot_descr).labels_\n",
    "onehot_score = silhouette_score(onehot_descr, onehot_labels)\n",
    "print(\"One-Hot Encoding: \"+str(onehot_score))\n",
    "loss1 = np.mean(np.absolute(np.subtract(onehot_labels, list(1-gr_truth))))\n",
    "print(\"0-1 Loss score:\" + str(loss1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the dummy encoding is better than one-hot. The only plausible reason is that our one-hot encoding increases our feature size too much thus increasing our vectors' dimensions. Even if the dummy encoding is not adapted for distance computations, it gains in the low space dimension.\n",
    "\n",
    "We will now try to visualize our clustering and compare it to the ground truth clustering. In order to visualize to latters, we will apply a PCA to apply a dimensionality reduction to 2 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'onehot_descr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-9ee11d3b8f38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Feature Transformation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monehot_descr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdata_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monehot_descr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_pca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'component1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'component2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'onehot_descr' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Feature Transformation\n",
    "pca = PCA(n_components=2).fit(onehot_descr) \n",
    "data_pca = pca.transform(onehot_descr)\n",
    "df = pd.DataFrame(data_pca, columns=['component1', 'component2'])\n",
    "\n",
    "#Figure\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(12,5))\n",
    "\n",
    "#Ground Truth Figure\n",
    "df_truth = pd.concat([gr_truth.reset_index(), df], axis=1)\n",
    "df_truth_0 = df_truth[df_truth.y == 0]\n",
    "df_truth_1 = df_truth[df_truth.y == 1]\n",
    "df_truth_0.plot(kind=\"scatter\", x='component1', y='component2', color='c', label='White Skin', ax=ax1)\n",
    "df_truth_1.plot(kind=\"scatter\", x='component1', y='component2', color='m', label='Coloured Skin', ax=ax1)\n",
    "ax1.set_title('Ground Truth Distribution')\n",
    "\n",
    "#K-Means clusters\n",
    "dummy_labels = pd.DataFrame(dummy_labels)\n",
    "dummy_labels.columns = ['y']\n",
    "df_cl = pd.concat([dummy_labels, df], axis=1)\n",
    "df_cl_0 = df_cl[df_cl.y == 1]\n",
    "df_cl_1 = df_cl[df_cl.y == 0]\n",
    "df_cl_0.plot(kind=\"scatter\", x='component1', y='component2', color='c', label='White Skin', ax=ax2)\n",
    "df_cl_1.plot(kind=\"scatter\", x='component1', y='component2', color='m', label='Coloured Skin', ax=ax2)\n",
    "ax2.set_title('K-Means classification')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using K-means...BLABLABLA\n",
    "### Feature removal analysis\n",
    "TODO: choisir dummy ou onehot!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dummy_descr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-92d56ac71604>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtemp_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdummy_descr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_feats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrm_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dummy_descr' is not defined"
     ]
    }
   ],
   "source": [
    "temp_feats = dummy_descr.copy()\n",
    "cols = temp_feats.columns\n",
    "end = len(cols)\n",
    "rm_scores = {}\n",
    "for i in range(1,end):\n",
    "    temp = temp_feats[cols[:i]]\n",
    "    kmm = KMeans(n_clusters=2, random_state=1).fit(temp)\n",
    "    labels = kmm.labels_\n",
    "    rm_scores[end-i] = silhouette_score(temp,labels)\n",
    "print(rm_scores.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "We now plot the silhouette score against the number of features taken into account."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
