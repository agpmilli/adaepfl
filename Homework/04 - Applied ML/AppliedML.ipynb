{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Applied ML\n",
    "\n",
    "## Deadline\n",
    "Monday November 21, 2016 at 11:59PM\n",
    "\n",
    "## Important Notes\n",
    "* Make sure you push on GitHub your Notebook with all the cells already evaluated\n",
    "* Don't forget to add a textual description of your thought process, the assumptions you made, and the solution\n",
    "you plan to implement!\n",
    "* Please write all your comments in English, and use meaningful variable names in your code\n",
    "\n",
    "## Background\n",
    "In this homework we will gain experience on Applied Machine Learning, exploring an interesting dataset about soccer players and referees.\n",
    "You can find all the data in the `CrowdstormingDataJuly1st.csv` file, while you can read a thorough [dataset description here](DATA.md).\n",
    "Given that the focus of this homework is Machine Learning, I recommend you to first take a look at [this notebook](http://nbviewer.jupyter.org/github/mathewzilla/redcard/blob/master/Crowdstorming_visualisation.ipynb)\n",
    "containing a solid work in pre-processing + visualization of the given dataset. You are *not* allowed to just copy/paste the pre-processing steps\n",
    "performed by the notebook authors -- you are still supposed to perform your own data analysis for the homework. Still, I'm confident that consulting first\n",
    "the work done by expert data analysts will speed up tangibly your effort (i.e., they have already found for you many glitches in the data :)\n",
    "\n",
    "\n",
    "## Assignment\n",
    "1. Train a `sklearn.ensemble.RandomForestClassifier` that given a soccer player description outputs his skin color. Show how different parameters \n",
    "passed to the Classifier affect the overfitting issue. Perform cross-validation to mitigate the overfitting of your model. Once you assessed your model,\n",
    "inspect the `feature_importances_` attribute and discuss the obtained results. With different assumptions on the data (e.g., dropping certain features even\n",
    "before feeding them to the classifier), can you obtain a substantially different `feature_importances_` attribute?\n",
    "*BONUS*: plot the learning curves against at least 2 different sets of parameters passed to your Random Forest. To obtain smooth curves, partition\n",
    "your data in at least 20 folds. Can you find a set of parameters that leads to high bias, and one which does not?\n",
    "\n",
    "2. Aggregate the referee information grouping by soccer player, and use an unsupervised learning technique to cluster the soccer players in 2 disjoint\n",
    "clusters. Remove features iteratively, and at each step perform again the clustering and compute the silhouette score -- can you find a configuration of features with high silhouette\n",
    "score where players with dark and light skin colors belong to different clusters? Discuss the obtained results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------\n",
    "# Data Description\n",
    "\n",
    "From a company for sports statistics, we obtained data and profile photos from all soccer players (N = 2053) playing in the first male divisions of England, Germany, France and Spain in the 2012-2013 season and all referees (N = 3147) that these players played under in their professional career. We created a dataset of player–referee dyads including the number of matches players and referees encountered each other and our dependent variable, the number of red cards given to a player by a particular referee throughout all matches the two encountered each other.\n",
    " \n",
    "Player photos were available from the source for 1586 out of 2053 players. Players’ skin tone was coded by two independent raters blind to the research question who, based on their profile photo, categorized players on a 5-point scale ranging from “very light skin” to “very dark skin” with “neither dark nor light skin” as the center value. \n",
    "\n",
    "Additionally, implicit bias scores for each referee country were calculated using a race implicit association test (IAT), with higher values corresponding to faster white | good, black | bad associations. Explicit bias scores for each referee country were calculated using a racial thermometer task, with higher values corresponding to greater feelings of warmth toward whites versus blacks. Both these measures were created by aggregating data from many online users in referee countries taking these tests on [Project Implicit](http://projectimplicit.net).\n",
    "\n",
    "In all, the dataset has a total of 146028 dyads of players and referees. A detailed description of all variables in the dataset can be seen in the list below.\n",
    "\n",
    "## Variables:\n",
    "\n",
    "*playerShort* - short player ID\n",
    "\n",
    "*player* - player name\n",
    "\n",
    "*club* - player club\n",
    "\n",
    "*leagueCountry* - country of player club (England, Germany, France, and Spain)\n",
    "\n",
    "*birthday* - player birthday\n",
    "\n",
    "*height* - player height (in cm)\n",
    "\n",
    "*weight* - player weight (in kg)\n",
    "\n",
    "*position* - detailed player position\n",
    "\n",
    "*games* - number of games in the player-referee dyad\n",
    "\n",
    "*victories* - victories in the player-referee dyad\n",
    "\n",
    "*ties* - ties in the player-referee dyad\n",
    "\n",
    "*defeats* - losses in the player-referee dyad\n",
    "\n",
    "*goals* - goals scored by a player in the player-referee dyad\n",
    "\n",
    "*yellowCards* - number of yellow cards player received from referee\n",
    "\n",
    "*yellowReds* - number of yellow-red cards player received from referee\n",
    "\n",
    "*redCards* - number of red cards player received from referee\n",
    "\n",
    "*photoID* - ID of player photo (if available)\n",
    "\n",
    "*rater1* - skin rating of photo by rater 1 (5-point scale ranging from “very light skin” to “very dark skin”)\n",
    "\n",
    "*rater2* - skin rating of photo by rater 2 (5-point scale ranging from “very light skin” to “very dark skin”)\n",
    "\n",
    "*refNum* - unique referee ID number (referee name removed for anonymizing purposes)\n",
    "\n",
    "*refCountry* - unique referee country ID number (country name removed for anonymizing purposes)\n",
    "\n",
    "*meanIAT* - mean implicit bias score (using the race IAT) for referee country, higher values correspond to faster white | good, black | bad associations\n",
    "\n",
    "*nIAT* - sample size for race IAT in that particular country\n",
    "\n",
    "*seIAT* - standard error for mean estimate of race IAT\n",
    "\n",
    "*meanExp* - mean explicit bias score (using a racial thermometer task) for referee country, higher values correspond to greater feelings of warmth toward whites versus blacks\n",
    "\n",
    "*nExp* - sample size for explicit bias in that particular country\n",
    "\n",
    "*seExp* - standard error for mean estimate of explicit bias measure\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerShort</th>\n",
       "      <th>nclub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [playerShort, nclub]\n",
       "Index: []"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_descr = ['playerShort', 'player', 'club', 'leagueCountry', 'birthday', 'height', 'weight', 'position', 'photoID', 'rater1', 'rater2']\n",
    "ref_descr = ['refNum', 'refCountry', 'Alpha_3', 'meanIAT', 'seIAT', 'meanExp', 'nExp', 'seExp']\n",
    "\n",
    "players = pd.DataFrame(dyads[player_descr])\n",
    "referees = dyads[ref_descr]\n",
    "\n",
    "occurence = pd.DataFrame({'frequency':players.groupby(['playerShort', 'club']).size()}).reset_index()\n",
    "ch_club = pd.DataFrame({'nclub': occurence.groupby(['playerShort']).size()}).reset_index()\n",
    "ch_club = ch_club[~ch_club['nclub'] == 1]\n",
    "ch_club"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
