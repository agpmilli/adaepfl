{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Applied ML\n",
    "\n",
    "## Deadline\n",
    "Monday November 21, 2016 at 11:59PM\n",
    "\n",
    "## Important Notes\n",
    "* Make sure you push on GitHub your Notebook with all the cells already evaluated\n",
    "* Don't forget to add a textual description of your thought process, the assumptions you made, and the solution\n",
    "you plan to implement!\n",
    "* Please write all your comments in English, and use meaningful variable names in your code\n",
    "\n",
    "## Background\n",
    "In this homework we will gain experience on Applied Machine Learning, exploring an interesting dataset about soccer players and referees.\n",
    "You can find all the data in the `CrowdstormingDataJuly1st.csv` file, while you can read a thorough [dataset description here](DATA.md).\n",
    "Given that the focus of this homework is Machine Learning, I recommend you to first take a look at [this notebook](http://nbviewer.jupyter.org/github/mathewzilla/redcard/blob/master/Crowdstorming_visualisation.ipynb)\n",
    "containing a solid work in pre-processing + visualization of the given dataset. You are *not* allowed to just copy/paste the pre-processing steps\n",
    "performed by the notebook authors -- you are still supposed to perform your own data analysis for the homework. Still, I'm confident that consulting first\n",
    "the work done by expert data analysts will speed up tangibly your effort (i.e., they have already found for you many glitches in the data :)\n",
    "\n",
    "\n",
    "## Assignment\n",
    "1. Train a `sklearn.ensemble.RandomForestClassifier` that given a soccer player description outputs his skin color. Show how different parameters \n",
    "passed to the Classifier affect the overfitting issue. Perform cross-validation to mitigate the overfitting of your model. Once you assessed your model,\n",
    "inspect the `feature_importances_` attribute and discuss the obtained results. With different assumptions on the data (e.g., dropping certain features even\n",
    "before feeding them to the classifier), can you obtain a substantially different `feature_importances_` attribute?\n",
    "*BONUS*: plot the learning curves against at least 2 different sets of parameters passed to your Random Forest. To obtain smooth curves, partition\n",
    "your data in at least 20 folds. Can you find a set of parameters that leads to high bias, and one which does not?\n",
    "\n",
    "2. Aggregate the referee information grouping by soccer player, and use an unsupervised learning technique to cluster the soccer players in 2 disjoint\n",
    "clusters. Remove features iteratively, and at each step perform again the clustering and compute the silhouette score -- can you find a configuration of features with high silhouette\n",
    "score where players with dark and light skin colors belong to different clusters? Discuss the obtained results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------\n",
    "# Data Description\n",
    "\n",
    "From a company for sports statistics, we obtained data and profile photos from all soccer players (N = 2053) playing in the first male divisions of England, Germany, France and Spain in the 2012-2013 season and all referees (N = 3147) that these players played under in their professional career. We created a dataset of player–referee dyads including the number of matches players and referees encountered each other and our dependent variable, the number of red cards given to a player by a particular referee throughout all matches the two encountered each other.\n",
    " \n",
    "Player photos were available from the source for 1586 out of 2053 players. Players’ skin tone was coded by two independent raters blind to the research question who, based on their profile photo, categorized players on a 5-point scale ranging from “very light skin” to “very dark skin” with “neither dark nor light skin” as the center value. \n",
    "\n",
    "Additionally, implicit bias scores for each referee country were calculated using a race implicit association test (IAT), with higher values corresponding to faster white | good, black | bad associations. Explicit bias scores for each referee country were calculated using a racial thermometer task, with higher values corresponding to greater feelings of warmth toward whites versus blacks. Both these measures were created by aggregating data from many online users in referee countries taking these tests on [Project Implicit](http://projectimplicit.net).\n",
    "\n",
    "In all, the dataset has a total of 146028 dyads of players and referees. A detailed description of all variables in the dataset can be seen in the list below.\n",
    "\n",
    "## Variables:\n",
    "\n",
    "*playerShort* - short player ID\n",
    "\n",
    "*player* - player name\n",
    "\n",
    "*club* - player club\n",
    "\n",
    "*leagueCountry* - country of player club (England, Germany, France, and Spain)\n",
    "\n",
    "*birthday* - player birthday\n",
    "\n",
    "*height* - player height (in cm)\n",
    "\n",
    "*weight* - player weight (in kg)\n",
    "\n",
    "*position* - detailed player position\n",
    "\n",
    "*games* - number of games in the player-referee dyad\n",
    "\n",
    "*victories* - victories in the player-referee dyad\n",
    "\n",
    "*ties* - ties in the player-referee dyad\n",
    "\n",
    "*defeats* - losses in the player-referee dyad\n",
    "\n",
    "*goals* - goals scored by a player in the player-referee dyad\n",
    "\n",
    "*yellowCards* - number of yellow cards player received from referee\n",
    "\n",
    "*yellowReds* - number of yellow-red cards player received from referee\n",
    "\n",
    "*redCards* - number of red cards player received from referee\n",
    "\n",
    "*photoID* - ID of player photo (if available)\n",
    "\n",
    "*rater1* - skin rating of photo by rater 1 (5-point scale ranging from “very light skin” to “very dark skin”)\n",
    "\n",
    "*rater2* - skin rating of photo by rater 2 (5-point scale ranging from “very light skin” to “very dark skin”)\n",
    "\n",
    "*refNum* - unique referee ID number (referee name removed for anonymizing purposes)\n",
    "\n",
    "*refCountry* - unique referee country ID number (country name removed for anonymizing purposes)\n",
    "\n",
    "*meanIAT* - mean implicit bias score (using the race IAT) for referee country, higher values correspond to faster white | good, black | bad associations\n",
    "\n",
    "*nIAT* - sample size for race IAT in that particular country\n",
    "\n",
    "*seIAT* - standard error for mean estimate of race IAT\n",
    "\n",
    "*meanExp* - mean explicit bias score (using a racial thermometer task) for referee country, higher values correspond to greater feelings of warmth toward whites versus blacks\n",
    "\n",
    "*nExp* - sample size for explicit bias in that particular country\n",
    "\n",
    "*seExp* - standard error for mean estimate of explicit bias measure\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# IMPLEMENTATION\n",
    "## Supervised Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "import preprocessing_helper as preproc_helper\n",
    "import classifiers_helper as class_helper\n",
    "import aggregater_helper as aggr_helper\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = 'CrowdstormingDataJuly1st.csv'\n",
    "dyads = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Visualization of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dyads.ix[:5, :int(len(dyads.columns) / 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dyads.ix[:5, 14:len(dyads.columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the visualization of the data and the ipython notebook which previously worked on the same dataset, we observed that each data entry is a dyad between a player and a referee. They all contain a player ID, a referee ID, their respective descriptors and some informations about the dyad itself.\n",
    "\n",
    "We could define a dyad as a relationship between a player and a referee. A dyad can contain multiple encounters of the pair (player <-> referee) from different matches. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cleaning \n",
    "\n",
    "First of all, as we have (player <-> referee) dyads, a referee in our dataset should have arbitrated at least one match. This implies that we should find at least 22 dyads containing the given referee (a team has 11 players).\n",
    "We thus check that for each referee we obtain at least 22 dyads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "referees = pd.DataFrame(dyads.groupby(['refNum']).size())\n",
    "referees.columns = ['count']\n",
    "bad_refs = referees[referees['count'] < 22]\n",
    "nb_refs = len(referees)\n",
    "nb_badrefs = len(bad_refs)\n",
    "print(\"Total number of refs:\", nb_refs)\n",
    "print(\"Number of refs with missing data:\", nb_badrefs)\n",
    "print(\"Percentage of refs with missing data:\", 100*(nb_badrefs/nb_refs), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found 2149 referees contained in less than 22 dyads. We can consider these as missing data events. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dyads_w_rm = dyads.drop(bad_refs.index)\n",
    "nb_dyads = len(dyads)\n",
    "nb_dyads_wrm = len(dyads_w_rm)\n",
    "print(\"Number of dyads:\", nb_dyads)\n",
    "print(\"Number of dyads after deletions:\", nb_dyads_wrm)\n",
    "print(\"Percent of dyads lost:\", (100*(1-(nb_dyads_wrm/nb_dyads))),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that even that the referees to delete represented 68% of the set of referees, the percentage of lost dyads after a potential removal is only around 1.5%. We thus decide to apply the deletion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dyads = dyads.drop(bad_refs.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Defining the label\n",
    "\n",
    "Our goal is to define if a player has dark skin or light skin. We thus need to design a model and train it on a part of this data with predefined skin labels. We will take the columns 'rater1' and 'rater2' to define this label. As the model needs an output (a valid skin label) we need at least one of these columns to be valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dyads = dyads[~(np.isnan(dyads['rater1']) & np.isnan(dyads['rater2']))]\n",
    "dyads.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As we have two observations defining the skin's color for each player, we want to aggregate them but first we have to check if there exists disparities between them. We also check what are the different values given by each rater."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"The max difference between two raters is\", (dyads['rater1']-dyads['rater2']).max())\n",
    "print(\"Rating values given by rater 1\", dyads['rater1'].unique())\n",
    "print(\"Rating values given by rater 2\", dyads['rater2'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scale is going from 0 to 1 with a step of 0.25 and the max difference is 0.25.\n",
    "Therefore we cannot find a case where there are opposite opinions about a player (one black, the other white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose to transform this scale of rating into binary labels. We consider our model to predict more of a white/coloured ouput. We choose to take the mean of these values and if the result is smaller than 0.5 we want to output 0 ('white') and if it is greater than 0.5 output 1 ('black/coloured')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dyads['y'] = (dyads['rater1'] + dyads['rater2']) / 2 \n",
    "dyads.loc[dyads['y'] < 0.5, 'y'] = 0\n",
    "dyads.loc[dyads['y'] >= 0.5, 'y'] = 1\n",
    "dyads.drop(['rater1', 'rater2'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training the classifier - Round one\n",
    "Now that we have clean the data, we can try to create a classifier on it and train it. We first pop the labels, then before label encoding the object columns in the original dataframe, we fill them first with the string 'Unknown' if we encounter a NaN value.\n",
    "\n",
    "Once the object columns are label encoded, we still fill the NaN values with -999. This is an arbitrary value we choose, since every column should not contain a negative value, it behaves as if it was not known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dyads_encoded = dyads.copy()\n",
    "dyads_encoded = preproc_helper.fill_na_columns(dyads_encoded, ['position', 'Alpha_3'], ['Unknown', 'Unknown'])\n",
    "labels = dyads_encoded.pop('y')\n",
    "dyads_encoded = preproc_helper.label_encode(dyads_encoded, list(dyads_encoded.select_dtypes(include=['object']).columns))\n",
    "dyads_encoded.fillna(-999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=10)\n",
    "scores = cross_val_score(classifier, dyads_encoded, labels, cv=10)\n",
    "print(\"Cross-val score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier score is impressive. Let's look at the important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Feature Importances\n",
    "class_helper.plot_importances(classifier, dyads_encoded, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we train our model with the dyads it means that a same player can be in the train and in the test dataset at the same time, so it's logical that the classifier uses the player name and its unique related informations (birthday, photoID, playerShort) to classify.\n",
    "\n",
    "As such the model does not make sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training the classifier - Round two\n",
    "\n",
    "As seen before the model does not make sense. Hence we move to an approach where we transform our data into a frame with an entry per player. Therefore, this implies, aggregating the dyads players while applying different aggregation functions per columns based on the information it contains. We will thus need to make some choices of interpretation to do the latter.\n",
    "\n",
    "#### 4.1 Aggregating and cleaning the data\n",
    "\n",
    "We first aggregate the dyads by players while appending their column informations into arrays. We also need  to not reorder the arrays to keep a mapping between a referee and its informations concerning the player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "players = dyads.groupby(['playerShort'])\n",
    "players = preproc_helper.groups_to_lists(players, 'playerShort')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the important features above, some of the columns are unique and represents directly a player. It means that they won't help to classify them. So we decide to drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "naive_data = players.drop(['birthday', 'player', 'photoID', 'Alpha_3', 'refCountry','index', 'refNum', 'nIAT', 'nExp'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a repetition of values for some columns that are supposed to be constant: \n",
    "weight, height, club. We check if the respective lists of those columns per player contain the same value or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(preproc_helper.has_same_value(naive_data['height']))\n",
    "print(preproc_helper.has_same_value(naive_data['weight']))\n",
    "print(preproc_helper.has_same_value(naive_data['y']))\n",
    "print(preproc_helper.has_same_value(naive_data['club']))\n",
    "print(preproc_helper.has_same_value(naive_data['leagueCountry']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, height and weight can differ for a given player. Is it because the list contains NaN or just different values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(preproc_helper.has_nan(naive_data['height']))\n",
    "print(preproc_helper.has_nan(naive_data['weight']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are NaNs in the height and weight columns for some players. We will replace those by their correct height and weight if we have them in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "naive_data['height'] = preproc_helper.replace_nan(naive_data['height'])\n",
    "naive_data['weight'] = preproc_helper.replace_nan(naive_data['weight'])\n",
    "\n",
    "print(preproc_helper.has_nan(naive_data['height']))\n",
    "print(preproc_helper.has_nan(naive_data['weight']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no more nan values in those columns but are all the values the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(preproc_helper.has_same_value(naive_data['height']))\n",
    "print(preproc_helper.has_same_value(naive_data['weight']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not yet, let's see if there are players with no height or weight. And drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_height = pd.DataFrame(naive_data['height'].apply(lambda row: len(set(row))))\n",
    "player_nan_height = unique_height[unique_height['height']==0]\n",
    "unique_weight = pd.DataFrame(naive_data['weight'].apply(lambda row: len(set(row))))\n",
    "player_nan_weight = unique_weight[unique_weight['weight']==0]\n",
    "\n",
    "list_diff = set(list(player_nan_weight.index.values) + list(player_nan_height.index.values))\n",
    "naive_data = naive_data.drop(list_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now they all have the same value so we will represent it by the first element of each list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Reducing\n",
    "We apply different aggregation functions on our columns:\n",
    "- As discussed, the columns  club, leagueCountry, height and weight are constants. We only take the first element of the array. This is also the case for y since a player do not change skin color over time.\n",
    "- Since the player's position may change over time, we decide to apply a majority vote on the list of his positions. We also create a \"Unknown\" position class for the Na cases.\n",
    "- The columns games, victories, ties, defeats, goals, yellowCards, redCards and yellowReds are simply summed.\n",
    "- seIAT and seExp becomes the standard deviation of the meanIAT and meanExp a player has.\n",
    "- We take the average of meanIAT and meanExp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "naive_data['y'] = naive_data['y'].apply(lambda x: int(x[0]))\n",
    "naive_data['club'] = naive_data['club'].apply(lambda x: x[0])\n",
    "naive_data['leagueCountry'] = naive_data['leagueCountry'].apply(lambda x: x[0])\n",
    "naive_data['height'] = naive_data['height'].apply(lambda x: x[0])\n",
    "naive_data['weight'] = naive_data['weight'].apply(lambda x: x[0])\n",
    "#majority vote\n",
    "naive_data['position'] = naive_data['position'].apply(mode)\n",
    "naive_data['position'].fillna(\"Unknown\", inplace=True)\n",
    "naive_data['games'] = naive_data['games'].apply(lambda x: sum(x))\n",
    "naive_data['victories'] = naive_data['victories'].apply(lambda x: sum(x))\n",
    "naive_data['ties'] = naive_data['ties'].apply(lambda x: sum(x))\n",
    "naive_data['defeats'] = naive_data['defeats'].apply(lambda x: sum(x))\n",
    "naive_data['goals'] = naive_data['goals'].apply(lambda x: sum(x))\n",
    "naive_data['yellowCards'] = naive_data['yellowCards'].apply(lambda x: sum(x))\n",
    "naive_data['yellowReds'] = naive_data['yellowReds'].apply(lambda x: sum(x))\n",
    "naive_data['redCards'] = naive_data['redCards'].apply(lambda x: sum(x))\n",
    "naive_data['seIAT'] = naive_data['meanIAT'].apply(np.std)\n",
    "naive_data['seExp'] = naive_data['meanExp'].apply(np.std)\n",
    "naive_data['meanIAT'] = naive_data['meanIAT'].apply(np.mean)\n",
    "naive_data['meanExp'] = naive_data['meanExp'].apply(np.mean)\n",
    "naive_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training our classifier, we drop the last NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "naive_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = naive_data.pop('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We encode our categorical data columns. The columns club, leagueCountry and position are supposed to be categorical data. We could dummily encode them with indices as scikit's label_encoding does. However, sklearn's RandomForestClassifier consider those values as continuous. At a given branch, it will separate the obtained values through intervals making the distance between indices important.\n",
    "Therefore we decide to one-hot encode our data. It slightly increases our feature dimensions but will reduce our bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoded_naive_data = preproc_helper.label_encode(naive_data, list(naive_data.select_dtypes(include=['object']).columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier: check this out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Classifier then CV K-Fold (k=3, default)\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "scores = cross_val_score(clf, encoded_naive_data, labels, cv=20)\n",
    "print(\"Cross-val score\")\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we got a score around 79% (that makes more sense) but we know that we are losing informations on the cards given by different referees. It means that for a player the value of a card given by a \"racist\" referee is the same as the value of a card given by a \"not racist\" referee. We don't want to lose this information, so we will need to ponder the cards using the \"racist\" value given for a referee."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3 Ponderation of cards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we normalize the value of meanIAT and meanEXP in our dyads dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm_dyads = dyads.copy()\n",
    "norm_dyads['meanIATNorm'] = (norm_dyads['meanIAT'] - norm_dyads['meanIAT'].min()) / (norm_dyads['meanIAT'].max() - norm_dyads['meanIAT'].min())\n",
    "norm_dyads['meanExpNorm'] = (norm_dyads['meanExp'] - norm_dyads['meanExp'].min()) / (norm_dyads['meanExp'].max() - norm_dyads['meanExp'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm_dyads['refScore']=(norm_dyads['meanIAT']+norm_dyads['meanExp'])/2\n",
    "norm_dyads['yellowCardsPonder']=norm_dyads['refScore'] * norm_dyads['yellowCards']\n",
    "norm_dyads['redCardsPonder']=norm_dyads['refScore'] * norm_dyads['redCards']\n",
    "norm_dyads['yellowRedsPonder']=norm_dyads['refScore'] * norm_dyads['yellowReds']\n",
    "#norm_dyads.drop(['yellowCards', 'redCards', 'yellowReds'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before we aggregate this dyad data to get an entry per player. (We did a function to not double the size of the notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_ = {('y') : lambda x: int(x[0]), \n",
    "         ('club', 'leagueCountry', 'height', 'weight') : lambda x: x[0],\n",
    "         ('position') : mode,\n",
    "         ('games', 'victories', 'ties', 'defeats', 'goals', 'yellowCards', 'yellowReds', 'redCards', 'yellowCardsPonder', 'yellowRedsPonder', 'redCardsPonder') : sum,\n",
    "         (('seIAT', 'meanIAT'), ('seExp', 'meanExp')) : np.std,\n",
    "         ('meanIAT', 'meanExp') : np.mean}\n",
    "#players_norm = aggr_helper.aggregate_dyads_to_players(norm_dyads, dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "players_norm.drop(['meanIATNorm', 'meanExpNorm'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_norm = players_norm.pop('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_encode_norm = ['club', 'leagueCountry','position']\n",
    "encoded_data_norm = pprh.one_hot_encode(players_norm, to_encode_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Classifier then CV K-Fold (k=3, default)\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "scores = cross_val_score(clf, encoded_data_norm, labels_norm, cv=8)\n",
    "print(\"Cross-val score\")\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have satisfying data preprocessing and classification. We will look at the influence of the features on our model. In other words, we will measure the feature importances as well as the model behaviour in the case of feature modifications (mainly deletion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Feature Importances\n",
    "clfh.plot_importances(clf, encoded_data_norm, labels_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remark that the features that often comes at the top of our plot are the two standard deviation of IAT and Exp and also their mean value. Let's now tweak our data by removing/encoding/adding some columns and see if we can get different important features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we will try to not use the One Hot Encoder and just drop the column we were encoding before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "players_norm_no_encoding = players_norm.drop(to_encode, axis=1)\n",
    "scores = cross_val_score(clf, players_norm_no_encoding, labels_norm, cv=8)\n",
    "print(\"Cross-val score\")\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Feature Importances\n",
    "clfh.plot_importances(clf, players_norm_no_encoding, labels_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then try to not encode the column using Hot Encoder but just using Label Encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_encoded_data_norm = pprh.label_encode(players_norm, to_encode_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(clf, label_encoded_data_norm, labels_norm, cv=8)\n",
    "print(\"Cross-val score\")\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Feature Importances\n",
    "clfh.plot_importances(clf, label_encoded_data_norm, labels_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to build a model where we only have the characteristics of the player itself and not the referee informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_encoded_data_norm = pprh.label_encode(players_norm, to_encode_norm)\n",
    "player_characteristics = label_encoded_data_norm.drop(['seIAT', 'meanIAT', 'meanExp', 'seExp', 'yellowCardsPonder', 'redCardsPonder', 'yellowRedsPonder'], axis=1)\n",
    "#Classifier then CV K-Fold (k=3, default)\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "scores = cross_val_score(clf, player_characteristics, labels_norm, cv=8)\n",
    "print(\"Cross-val score\")\n",
    "print(scores.mean())\n",
    "#Feature Importances\n",
    "clfh.plot_importances(clf, player_characteristics, labels_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is less accurate but still surprisingly high. In this case the important features are different. It looks like the classifier uses the results of the matches (victories/ties/defeats) as its best features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the learning curves for the player characteristics and the dataset with all the columns (including the referee country IAT, Exp data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Feature Importances\n",
    "import plot_learning_curve as plc\n",
    "(X_train, X_test, y_train, y_test, values, labels) = clfh.importances(clf, player_characteristics, labels_norm)\n",
    "plc.plot_learning_curve(clf, 'Learning curves on player characteristics (RandomForestClassifier)',X_train, y_train, cv=20).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Feature Importances\n",
    "import plot_learning_curve as plc\n",
    "(X_train, X_test, y_train, y_test, values, labels) = clfh.importances(clf, encoded_data_norm, labels_norm)\n",
    "plc.plot_learning_curve(clf, 'Learning curve on all data (RandomForestClassifier)',X_train, y_train, cv=20).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bias in the first plot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Unsupervised Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
